\documentclass[10pt,conference,compsocconf]{IEEEtran}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage[english]{babel}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
%\let\labelindent\relax
%\usepackage{enumitem}
\let\proof\relax
\let\endproof\relax 
\usepackage{amsthm}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{multicol}
%\let\subcaption\relax
\usepackage[font=small]{subcaption}
\usepackage{graphicx}
\usepackage[hidelinks,bookmarks=false,pdfpagelabels]{hyperref}
\usepackage[nocompress]{cite}
\usepackage{listings}

% definition environment
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{invariant}{Invariant}

% typewriter font family that support hyphenation
%\newcommand\textvtt[1]{{\normalfont\fontfamily{cmvtt}\selectfont #1}}
\hyphenation{MD-List} 
\hyphenation{skip-list}

\algtext*{EndWhile}
\algtext*{EndFor}
\algtext*{EndIf}
\algtext*{EndFunction}
\newcommand\NIL{\text{NIL}}
\newcommand\TRUE{\text{\textbf{true}}}
\newcommand\FALSE{\text{\textbf{false}}}
\newcommand\BREAK{\text{\textbf{break}}}
\newcommand\CONTINUE{\text{\textbf{continue}}}
\newcommand\AND{\;\text{\textbf{and}}\;}
\newcommand\OR{\;\text{\textbf{or}}\;}
\newcommand\INSERT{\text{\textbf{Insert}}}
\newcommand\DELETE{\text{\textbf{Delete}}}
\newcommand\SUCCEED{\text{\textbf{Succeeded}}}
\newcommand\FAIL{\text{\textbf{Failed}}}
\newcommand\INPROGRESS{\text{\textbf{InProgress}}}
\algrenewcommand\algorithmicindent{1em}

\algblockdefx[StructBlock]{Struct}{EndStruct} [1]{\textbf{struct} #1} [0]{}
\algtext*{EndStruct}
\algblockdefx[EnumBlock]{Enum}{EndEnum} [1]{\textbf{enum} #1} [0]{}
\algtext*{EndEnum}
\algblockdefx[ClassBlock]{Class}{EndClass} [1]{\textbf{class} #1} [0]{}
\algtext*{EndClass}
\algblockdefx[MacroBlock]{Define}{EndDefine} [1]{\textbf{define} #1} [0]{}
\algtext*{EndDefine}
\algblockdefx[InlineBlock]{Inline}{EndInline} [2]{\textbf{inline function} \textsc{#1}(#2)} [0]{}
\algtext*{EndInline}
\algblockdefx[SwitchBlock]{Switch}{EndSwitch} [1]{\textbf{switch} (#1)} [0]{}
\algtext*{EndSwitch}

\begin{document}

\title{Lock-free Transactions without Aborts for Linked Data Structures}

\author{\IEEEauthorblockN{Deli~Zhang\hspace{14pt} Damian~Dechev}
    \IEEEauthorblockA{Department of Electrical Engineering and Computer Science\\
        University of Central Florida\\
        Orlando, FL 32817, USA\\
    de-li.zhang@knights.ucf.edu \hspace{14pt} dechev@eecs.ucf.edu}
}

\maketitle

\begin{abstract}
    Non-blocking data structures allow scalable and thread-safe accesses to shared data. 
    They provide individual operations that appear to execute atomically.
    However, it is often desirable to execute multiple operations atomically in a transactional manner.
    This is nearly impossible without revamping the data structures' intricate underlying design.
    In this work, we present a novel technique for implementing high-performance lock-free transactional linked data structures.
    In our approach, transactions insert into the data structure logically inactive nodes, which are invisible to operations outside the scope of the transaction.
    We implement a shared transaction descriptor that atomically activates all nodes within a transaction upon committing.
    Comparing to generic approaches, such as software transactional memory (STM) and transactional boosting, our approach leverages the semantic knowledge of the data structure implementation to eliminate the overhead of false conflict and operation roll back.
\end{abstract}

%\category{D.1.3}{Concurrent Programming}{Algorithms}
%\terms{Algorithms, Performance}
\begin{IEEEkeywords}
    Concurrent Data Structure, Transactional Memory, Lock-free 
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}
With the growing prevalence of multi-core systems numerous highly concurrent non-blocking data structures have emerged~\cite{linden2013skiplist,ellen2010non,braginsky2012lock,zhang2015lockfree,michael2002high}.
Researchers and advanced users have been using libraries like LibCDS~\footnote{http://libcds.sourceforge.net/}, Tervel~\footnote{http://ucf-cs.github.io/Tervel/} and Intel's TBB~\footnote{https://www.threadingbuildingblocks.org/}, which are packed with efficient concurrent implementations of most common data structures.
High level programming languages such as C\#, JAVA and Scala also start to provide concurrent libraries, which allow users who are unaware of the pitfalls of concurrent programming to take advantage of the performance benefits safely.
These libraries provide operations that appear to execute atomically when invoked individually.
However, they fall short when users need to execute a sequence of operations atomically (i.e., compose operations in the manner of transaction).
For example, given a linearizable map data structure, the following code snippet implementing a simple \texttt{ComputeIfAbsent} pattern~\cite{golan2013concurrent} is error prone.
\begin{lstlisting}[basicstyle=\small,language=JAVA]
    if(!map.containsKey(key)) {
        value = ... // some computation
        map.put(key, value);
    }
\end{lstlisting}
The intention of this code is to compute a value and store it in the map, if and only if the map does not already contain the given key.
The code snippet fails to achieve this since another thread may have stored a value associated with the same key right after the execution of \texttt{containsKey} and before the invocation of \texttt{put}.
As a result, the thread will overwrite the value inserted by the other concurrent thread upon the completion of \texttt{put}.
Programmers might experience unexpected behavior due to the violation of the intended semantics of \texttt{ComputeIfAbsent}.
Many Java programs encounter bugs that are caused by such non-atomic composition of operations~\cite{shacham2011testing}.
Because of such hazards, often users are forced to fall back to locking and even coarse-grained locking, which has a negative impact on performance and annihilates the non-blocking progress guarantees provided by some concurrent containers.

The problem of implementing high-performance transactional data structures~\footnote{Also referred as \emph{atomic composite operations}~\cite{golan2013concurrent}} is important and has recently gained much attention~\cite{golan2013concurrent,bronson2010transactional,herlihy2008transactional,gramoli2013composing,golan2015automatic,hassan2014integrating,koskinen2010coarse}. 
In this paper, we refer to a sequence of atomic operations as a transaction.
We consider a concurrent data structure `transactional' if it executes transactions 1) atomically (i.e., if one operation fails, the entire transaction should abort), and 2) in isolation (i.e., concurrent executions of transactions appears to take effect in some sequential order).
%Supporting transactional operations in concurrent sets~\cite{bronson2011composable} are especially rewarding, because they are the fundamental building blocks of in-memory databases~\cite{}.

General purpose software transactional memory (STM)~\cite{shavit1997software,herlihy2003software} can be used to easily construct transactional data structures from their sequential counterparts: any operations executed within an STM transaction are guaranteed to be transactional.
Despite the appeal of straightforward implementation, this approach has not gained practical acceptance due to its significant runtime overhead~\cite{cascaval2008software}.
An STM instruments threads' memory accesses by recording the locations a thread read in a \emph{read set}, and the locations it wrote in a \emph{write set}. 
Conflicts are detected among the \emph{read/write sets} of different threads. 
In the presence of conflicts, only one transaction is allowed to commit while the others are aborted and restarted.
Apart from the overhead of memory instrumentation, excessive transaction aborts in the presence of data structure "hot-spots" (memory locations that are constantly accessed by threads, e.g., the head node of a linked list) limit the overall concurrency~\cite{herlihy2008transactional}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\columnwidth]{figure/stmconflict.pdf}
    \caption{False Conflict in STM}
    \label{fig:stmconflict}
\end{figure}
Figure~\ref{fig:stmconflict} illustrates such an example.
It shows a set implemented as an ordered linked list, where each node has two fields, an integer value and a pointer to the next node.
The initial state of the set is $\{0,3,6,9,10\}$.
Thread 1 and Thread 2 intend to insert 4 and 1, respectively.
Since these two operations commute, it is feasible to execute them concurrently~\cite{clements2015scalable}.
In fact, concurrent linked list implementations employing lock-free~\cite{michael2002high} or fine-grained locking synchronizations~\cite{bayer1977concurrency} allow concurrent execution of the two operations.
Nevertheless, these operations have a read/write conflict and the STM has to abort one of them. 
The inherent disadvantage of STM concurrency control is that low-level memory access conflicts do not necessarily correspond to high-level semantic conflicts.
%Some efforts have be done to alleviate the situation by somehow inferring part of the semantic either through user annotation or.

Transactional boosting~\cite{herlihy2008transactional} is a methodology for transforming linearizable concurrent data structures into transactional data structures.
The basic idea behind boosting is intuitive: if two operations commute they are allowed to proceed without interference (i.e., synchronization happens at the operation level); otherwise they need to be synchronized at the transaction level.
It treats the original data structure as a black box and uses \emph{abstract locking} to ensure that non-commutative method calls do not occur concurrently. 
For each operation in a transaction, the boosted data structure calls the corresponding method of the underlying linearizable data structure after acquiring the abstract lock associated with that call. 
A transaction aborts when it fails to acquire an abstract lock, and it recovers from failure by invoking the inverses of already executed calls. 
This approach eliminates the excessive aborts associated with STM-based transactional data structures, but it still suffers from performance penalties associated with the rolling back of partially executed transactions.
Moreover, in case of non-blocking algorithms, the progress guarantee of the boosted data structure is degraded because of the use of locks for transactional-level synchronization.
%\begin{figure}[h]
    %\centering
    %\includegraphics[width=0.9\columnwidth]{figure/boosting.pdf}
    %\caption{Rollbacks in Transactional Boosting}
    %\label{fig:boosting}
%\end{figure}
%In the boosted linked list shown in Figure~\ref{fig:boosting}, the abstract lock is pertaining to each key.  
%thread 1 tries to execute \texttt{Insert(1)} and \texttt{Insert(4)} in a transaction while thread 2 tries to execute \texttt{Remove(9)} and \texttt{Insert(4)} transactionally.
 
In this paper we present a methodology to implement lock-free transactional linked data structures by relying only on the single-word \texttt{ComapreAndSwap} synchronization primitive.
By a linked data structure we mean one that comprises a set of data nodes organized by references. 
Each node has one inbound reference and can have one (e.g., linked list), two (e.g., binary tree), or more (e.g., B-tree and multi-dimensional linked list) outbound references.
Consider the three basic write operations one can perform on a node: insertion, deletion, and update.
In existing lock-free implementations, these operations act directly on different fields of a node, and the effects are rendered immediately in the state of the abstract data type (ADT).
We address the two key challenges of supporting transactional operations without rollbacks: 1) transaction isolation requires that the effects of an operation is invisible to operations outside the transaction scope before the transaction successfully commits; and 2) delete and update operations require indirection such that their effect can be muted in case of transaction failure.

At the core of our approach, we associate a logical status with each node by embedding \emph{transaction descriptors} in them.
A descriptor is shared among all the nodes within the same transaction, and it stores the operation context as well as a flag indicating the phase of the transaction (e.g., in-progress, succeeded or failed).
A node's logical status denotes how other concurrent operations interpret the node's content.
%and it is determined by the type of operation and the phase of the transaction.
Based on the phase of the transaction, we categorize nodes into logically active ones and inactive ones.
The logically active nodes are those with a descriptor indicating transaction success, while the logically inactive nodes are those with a descriptor indicating an in-progress or failed transaction.
Logically inactive nodes will be treated by operations outside the transaction scope as ``invisible'', thus they do not affect the state of the ADT. 
As a result, the state of the ADT is determined by only the logically active nodes.
For example, if a transaction inserted a new node but failed afterwards due to semantic conflicts, the newly inserted node will have a descriptor indicating the transaction failure.
All subsequent operations will be coordinated as if the node does not exists.
Moreover, we design an lock-free node replace algorithm that allows update or delete operations to insert new nodes that replace exiting nodes in the data structure.
This provides a layer of indirection which enable us to engineer all three write operations in a uniform manner.
For example, if a transaction needs to delete a existing node, it replaces the old node with a new node which has the same key as the to-be-deleted node, but a new transaction descriptor pertaining to itself.
If this transaction succeeds, the logical status of the newly inserted node will be interpreted as deleted. 
Otherwise, it implies a failed deletion hence the logical existence of the node.

Our approach has the following algorithmic characteristics that aim provide comparable level of concurrency as the state-of-the-art lock-free data structures.
\begin{itemize}
    \item In-progress and failed transactions do not alter the state of abstract date types
    \item Transactions do not abort upon node access conflict; instead they help delayed operations to achieve lock-freedom
    \item Rolling back executed operations in failed transactions is not necessary as the nodes will remain logically inactive
\end{itemize}

In our experimental evaluation, we compare transactional linked list and binary search trees built using RSTM, transactional boosting, and out approach on a 64-core NUMA and a 12-core SMP system for three types of workload. 
%The result shows that on the NUMA system our algorithm outperforms the alternative approaches by an average of $50\%$ under high concurrency.
%On the SMP system, our algorithm achieves the same level of performance as the best skiplist-based approach for mixed workload and outperforms the alternatives for insert-only workload. 

The rest of the paper is organized as follows. 
In Section~\ref{sec:related}, we review existing approaches on constructing transactional data structures.
In Section~\ref{sec:algorithm}, we explain our algorithms in details.
We present the transactional linked list and binary search tree in Section~\ref{sec:application}.
We reason about their correctness and progress properties in Section~\ref{sec:correctness}.
The performance evaluation and result analysis is given in Section~\ref{sec:experiment}.
We conclude the paper in Section~\ref{sec:conclusion}.

\section{Related Work}
\label{sec:related}
%1: lock-free data structures with thread-level synchronization techniques
%2: transaction synchronization
A transactional execution of data structure operations can be seen as a restricted form of \emph{software transactions}~\cite{harris2010transactional}.
%The scope of the data and the are well defined according to the semantics of the data structure.
%This opens up opportunity for enabling data structure specific optimizations. 
%The users of concurrent data structures have to devise their own concurrency control scheme. 
Straightforward generic constructions can be implemented by executing all shared memory accesses in \emph{atomic sections}, which can employ either optimistic (e.g., STM) or pessimistic (e.g., lock inference) concurrency control.
More sophisticated approaches~\cite{bronson2010transactional,herlihy2008transactional,golan2015automatic} exploit semantic conflict detection for transaction level synchronization to reduce benign conflicts.
In our work, we benefit from both fine-grained thread level synchronization and semantic conflict detection to implement transactional linked data structures without the overhead of atomic section synchronizations.

\subsection{Transactional Memory}
Initially proposed as a set of hardware extensions by Herlihy and Moss~\cite{herlihy1993transactional}, transactional memory was intended to facilitate the development of lock-free data structures.
%Even with Intel's recent release of commercial support of best-effort hardware transaction memory (HTM) in their Haswell processors, 
However, due to current HTM's cache-coherency based conflict detection mechanism, transactions are subject to spurious failures during page faults and context switches~\cite{dice2009early}.
This along with excessive aborts under moderate contention~\cite{christina2015resource} make HTM less desirable for implementing transactions in non-blocking data structures.
Thus, considerable amount of work and ingenuity has instead gone into designing lock-free data structures using low-level synchronization primitives such as \texttt{CompareAndSwap}, which empowers researchers to devise algorithm-specific fine-grained concurrency control schemes.

The first software implementation of transactional memory was proposed by Shavit and Touitou~\cite{shavit1997software}, which only supports a static set of data items.
Over the years, improvements have been achieved in terms of functionality~\cite{herlihy2003software}, consistency properties~\cite{guerraoui2008correctness}, progress guarantees~\cite{marathe2006lowering}, and performance~\cite{saha2006mcrt,dice2006transactional}. 
Despite heavy research investment, there is an increasing realization that the read/write conflicts inherently provide insufficient support for concurrency when shared objects are subject to contention~\cite{koskinen2010coarse}.
Meanwhile as design choices have been exhaustedly explored~\cite{marathe2004qualitative,marathe2004design}, other limitations faced by STM with regard to usability~\cite{Rossbach2010transactional}, performance~\cite{cascaval2008software}, and expressiveness~\cite{guerraoui2008obstruction} also began to surface.
It has been suggested that STM may not deliver the promised efficiency and simplicity for every scenario, and multitude of approaches should be explored catering to different needs~\cite{attiya2010inherent}.
%Unlike STM-based data structures, our approach eliminate the need to abort transactions.

\subsection{Lock Inference}
The above mentioned STM implementations are typically \emph{optimistic}, which means they execute under the assumption that interferences are unlikely to occur.
They also maintain expensive undo-logs to allow rollback in case a transaction do experience interference.
In light of this shortcoming, pessimistic alternatives based on lock inference has been proposed~\cite{mccloskey2006autolocker}.
These algorithms synthesize enough locks through static analysis to prevent data races in atomic sections.
The choice of locking granularity will have an impact on the trade-off between concurrency and overhead.
Some approaches require programmers' annotation~\cite{golan2013concurrent} to specify the granularity, others automatically infer locks at a fixed granularity~\cite{emmi2007lock} or even multiple granularities~\cite{cherem2008inferring}.
Nevertheless, most work associate locks with memory locations, which may lead to reduced parallelism due to false conflict as seen in STM. 
Applying these approaches to real-world programs also faces scalability changes in the presence of large libraries ~\cite{gudka2012lock} because of the high cyclomatic complexity~\footnote{A measure of the number of linearly independent execution paths~\cite{mccabe1976complexity}.} involved in the static analysis process.
Moreover, the use of locks degrades any non-blocking progress guarantee one might expected from using a non-blocking library.
%Kempf2014combining combines lock inference and stm.

\subsection{Semantic Conflict Detection}
Considering the imprecise nature of data-base conflict detection, semantic-based approaches has been proposed to identify conflicts at high-level (e.g., two commutative operations would not raise conflict even though they may access and modify the same data) which enables greater parallelism.
Because semantically independent transactions may have structural conflicts, some other concurrency control mechanism must be used to protect accesses to the underlying data structure.
This results in a two-layer concurrency control.
Transactional boosting proposed by Herlihy~\cite{herlihy2008transactional} was the first dedicated treatment on building highly concurrent transactional data structures using a semantic layer of abstract locks. 
Transactional boosting is pessimistic in that it acquires locks eagerly before the method calls, but it still requires operation rollback because not all locks are acquires at once.
%PTB, black box design, forfiet data structure specific optimization, need to reverse operation upon failure
Koskinen et al.~\cite{koskinen2010coarse} later generalize this work and introduce a formal framework called coarse-grained transactions.
Hassan et al.~\cite{hassan2014developing} proposed an optimistic version of boosting, which employs a white box design and provide some performance benefits.
Other STM variants, such open nested transactions~\cite{ni2007open} supports a more relaxed transaction model that leverages some semantic knowledge based on programmer's input.
The relaxation of STM systems and its implication on composability has been studied by Gramoli et al.~\cite{gramoli2013composing}.
The work by Golan-Gueta et al.~\cite{golan2015automatic} apply commutativity specification obtained from programmers input to inferring locks for abstract data types.
All these approaches require the underlying data structure to be linearizable.
%Our approach, do not track read/write set, highly concurrent, Optimistic lock-free
%we leverage the semantic knowledge of the data structure implementation, 

\section{Algorithm}
\label{sec:algorithm}
Non-blocking algorithms for linked data structures have been extensively studied because their distribute memory layout provides access parallelism and good scalability under high levels of contention~\cite{linden2013skiplist,zhang2015lockfree,michael2002high}.
To the best of our knowledge, there is no non-blocking linked data structure that provides native support for transactions.
To ensure atomicity in non-blocking transaction execution without an additional layer of synchronization, a write operation needs to either ``hide'' its effect until the transaction commits or revert its modifications upon transaction failure.
We follow the former strategy because the latter requires extra coordinations between operations in different transaction in order to achieve isolation.
To effectively ``hide'' the newly inserted nodes before transaction completes, we embed a transaction-status-dependent logical flag in them. 
This is similar to the \emph{logical deletion} technique, which is used in~\cite{harris2001pragmatic} to ensure list integrity and in~\cite{linden2013skiplist,zhang2015lockfree} to speedup the deletion process.
Logical deletion encodes a binary logical status in a node's bit-marked next pointer, whereas our approach embeds a multi-value transaction status in the descriptor object shared among nodes.
The key challenge remains to design a deletion and update process that allow logically invisible modification.
We achieve this goal by having them insert nodes that are logically inactive instead of modify the data structure directly.
In this section we explain the basic data structures as well as two core procedures that are shared among different kinds of linked data structures.

\subsection{Data Structure}
We define the generic node structure used in the rest of the paper in Algorithm~\ref{alg:nodestructure}. 
A node contains a key-value pair, and an array of child pointers $child[N]$, where $N$ depends on the concrete data type (e.g., 1 for linked lists, 2 for binary trees, etc.)
It also stores a reference to the shared transaction descriptor object $desc$ and an index $opid$ that provide reference to the operation pertaining to this node (i.e., $desc.ops[opid]$ is the operation that inserted this node).
Finally, it has a reference $repl$ to the node it replaces (if it replaces anything).
The descriptor object~\cite{herlihy2012art} \textsc{Desc} is a data structure used in lock-free programming to announce steps that cannot be done by a single atomic instruction.
The functionalities of a transactional descriptor are two folds: 1) it stores all the necessary context for any thread to finish a pending transaction; and 2) it provides the transaction status shared among all nodes participated in the same transaction.
Each operation structure keeps a key-value pair for the operation and an enumeration of operation type, the value of which depends on the concrete data types.

\begin{algorithm}[h]
    \caption{Node Structures}
    \label{alg:nodestructure}
    \vspace{-0.2in}
    \begin{multicols}{2}
        \begin{algorithmic}[1]
            \Enum{Status}
            \State \textbf{InProgress}
            \State \textbf{Succeeded}
            \State \textbf{Failed}
            \EndEnum
            \Struct{Desc}
            \State \textbf{int} $size$
            \State \textbf{Stauts} $flag$
            \State \textbf{Operation} $ops[\;]$
            \EndStruct
            \Struct{Operation}
            \State \textbf{int} $type,key$
            \State \textbf{void*} $val$
            \EndStruct
            \Struct{Node}
            \State \textbf{int} $key,opid$
            \State \textbf{void*} $val$
            \State \textbf{Node*} $child[N],repl$
            \State \textbf{Desc*} $desc$
            \EndStruct
            \end{algorithmic}
    \end{multicols}
    \vspace{-0.15in}
\end{algorithm}

\begin{algorithm}[h]
    \caption{Pointer Marking}
    \label{alg:pointermarking}
    \begin{algorithmic}[1]
        \State \textbf{const int} $F_{adp} \gets \texttt{0x1}$
        \Define{SetMark}{$(p)$} $(p\;|\;F_{adp})$
        \EndDefine
        \Define{ClearMark}{$(p)$} $(p\;\&\;\sim F_{adp})$
        \EndDefine
        \Define{IsMarked}{$(p)$} $(p\;\&\;F_{adp})$
        \EndDefine
    \end{algorithmic}
\end{algorithm}

We employ the pointer marking technique described by Harris~\cite{harris2001pragmatic} to mark adopted child nodes as well as logically deleted nodes. 
The macros for pointer marking are defined in Algorithm~\ref{alg:pointermarking}.
The $F_{adp}$ flag is co-located with the $child$ pointers.

\subsection{Lock-free Node Replacement}
\label{sec:noderepl}
All write operations in our approach try to insert new nodes.
If no node with the same key exists, lock-free insertion can be done by simply swing the next pointer of the predecessor node~\cite{zhang2015lockfree,harris2001pragmatic}, but more often, nodes are inserted to replace an existing node in order to change its logical status.
For example, to delete the exiting node 4 from a linked list as shown in Figure~\ref{fig:nodedeletion} we insert a new node marked for logical deletion in place of the original node.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\columnwidth]{figure/deletion.pdf}
    \caption{Node Deletion}
    \label{fig:nodedeletion}
\end{figure}

\begin{algorithm}[h]
    \caption{Node Replace}
    \label{alg:replace}
    \begin{algorithmic}[1]
        \Function{Replace}{$\textbf{Node*}\;pred,\;\textbf{Node*}\;curr\;\textbf{Node*}\;n,\break\;\textbf{bool}\;replace,\;\textbf{int}\;d_p,\;\textbf{int}\;d_c$}
        \State $n.repl \gets replace = \TRUE \;?\; curr : \NIL$
        \State $n.child[d_c] \gets replace = \TRUE \;?\; \NIL : curr$
        \If {$\text{\textsc{CAS}}(\&pred.child[d_p],\;repl,\;n)$} \label{l:link}
        \State \Call{AdoptChild}{$n$} \label{l:adoptself}
        \State \Return \TRUE
        \Else
        \State \Return \FALSE
        \EndIf
        \EndFunction
        \Statex
        \Function{AdoptChild}{$\textbf{Node*}\;n$}
        %\If {$n = \NIL$}
        %\State \Return
        %\EndIf
        \State \textbf{Node*} $curr \gets n.repl$
        \If {$curr=\NIL \OR \textsc{IsMarked}(curr)$}
        \State \Return
        \EndIf
        \State \textsc{CAS}$(\&curr.repl,\; \NIL,\; \textsc{SetMark}(n)$ \label{l:adoptsetrepl}
        \State \textbf{Node*} $child \gets \NIL$
        \For {$i \in [0, N)$} \label{l:adoptionfor}
        \State $child \gets \textsc{FetchAndOr}(\&curr.child[i],\;F_{adp})$ \label{l:setadp} 
        \State $child \gets \textsc{ClearMark}(child)$
        \State $\text{\textsc{CAS}}(\&n.child[i],\;\NIL,\;child)$ \label{l:adopt}
        \EndFor
        \State $\textsc{CAS}(\&n.repl,\;curr,\;\NIL)$
        \EndFunction
        \end{algorithmic}
\end{algorithm}

%TODO: explain the helping mechanism of child adoption
%TODO: make Replace function also insert new node if the node to be replaced is NULL
This requires the child nodes of node being replaced to be transfered to the new node in a lock-free manner.
The \textsc{Replace} function inserts a new node $n$ to replace the $i$th child $repl$ of its predecessor $pred$.
We link $pred.child[i]$ to the new node on line~\algref{alg:replace}{l:link}, and proceed to adopt child nodes from $repl$ in the helper function \textsc{AdoptChild}.
Before a child pointer can be copied, we must safeguard it so that it cannot be changed by concurrent insertions while the copy is in progress.
This is done by setting the $F_{adp}$ flag in the child pointers (line~\algref{alg:replace}{l:setadp}).
Once the flag is set either by this thread or by other threads, the function proceeds to copy the pointer to $n$ (line~\algref{alg:replace}{l:adopt}). 
Finally, the descriptor field in $n$ is cleared to designate the operation's completion.

\subsection{Transaction Execution}
\label{sec:txnexec}
%The caveat is that the read operations need to check a node's status to ensure it is in a consistent status or even help the write operation to finish the remaining steps.
In our approach, we treat nodes as the natural units for conflict detection.
%; e.g., insert 3 modifies node 2, but update 3 modifies node 3
Write operations inserting nodes with different keys are allowed to execute concurrently.
Should conflicts among write operations occur, threads help finish the delayed transaction starting from the node in conflict.
The \textsc{ExecuteOps} function in Algorithm~\ref{alg:transaction} execute operations starting from $opid$ in the transaction descriptor $desc$.
The thread initiating the transaction will start from $opid=0$, while other thread might concurrently invoke this method to help unfinished operations with $opid\in[1,desc.size)$.
The method consists of a while loop (line~\algref{alg:transaction}{l:txnwhile}) that executes each operation in order.
The next operation will only be executed if the previous operation completes successfully.
Otherwise, it indicates some unsatisfied precondition and the transaction aborts. 
The concrete \textsc{ExecuteOp} function varies slightly among different data types.
We explain them in details in Section~\ref{sec:application}.
Once all operations completes successfully we atomically update the transaction status with a succeeded flag (line~\algref{alg:transaction}{l:txnsuccess}).

\begin{algorithm}[h]
    \caption{Transaction Execution}
    \label{alg:transaction}
    \begin{algorithmic}[1]
        \Function{ExecuteOps}{$\textbf{Desc*}\;desc,\;\textbf{int}\;opid$}
        \State $ret \gets \TRUE$
        \While {$desc.flag = InProgress$ $\AND ret \AND$ $opid < desc.size$} \label{l:txnwhile}
        \State $\textbf{Operation*} op \gets \&desc.ops[opid]$
        \State $ret \gets \Call{ExecuteOp}{op}$
        \State $opid \gets opid + 1$
        \EndWhile
        \If {$ret = \TRUE$}
        \State $\text{\textsc{CAS}}(\&desc.flag,\;InProgress,\;Succeeded)$ \label{l:txnsuccess}
        \Else
        \State $\text{\textsc{CAS}}(\&desc.flag,\;InProgress,\;Failed)$        
        \EndIf
        \EndFunction
        \end{algorithmic}
\end{algorithm}

\section{Application Examples}
\label{sec:application}
Following our approach, the key process to implement a transactional linked data structures based on the sequential algorithm involves 1) identifying the conditions that determine if a node is active; and 2) applying the aforementioned lock-free node replacement technique to convert the write operations.
The goal of the first step is to construct a sub-routine which helps operations to correctly recognize the logical status of a node.
The second step generates uniform write operations that share the same basic node insertion procedure and differ only in the trigger condition for insertion.

%TODO: define existing node and active node
\subsection{Linked List}
We now demonstrate the implementation of a transactional ordered linked list.
Algorithm~\ref{alg:listfind} lists the \texttt{Find} operation as well as four sub-routines that are shared among \texttt{Insert} and \texttt{Delete} operations.
\texttt{Find} determines if a node with the specific key exists.
The node traversal algorithm \texttt{LocatePred}\footnote{We use the notion of reference arguments marked by \textbf{ref}, which surfaces the modification of arguments done by the callee function in the caller function.} locates a node's immediate parent node $pred$ and child node $curr$. 
Similar to the sequential algorithm, termination condition is based on the comparison of the key values (line~\algref{alg:listfind}{l:listpredcheck}).
The child adoption step (line~\algref{alg:listfind}{l:listpredhelp}) is unique to the concurrent algorithm.
It ensures that the child pointer in $curr$ is up to date when read on line~\algref{alg:listfind}{l:listpredchild}

\begin{algorithm}[th]
    \caption{Linked List Find}
    \label{alg:listfind}
    \begin{algorithmic}[1]
        \Function{Find}{$\textbf{int}\;key,\;\textbf{Desc*}\;desc$}
        \State $\textbf{Node*}\;pred \gets \NIL,\;curr \gets head$
        \State \Call{LocatePred}{$pred,\;curr,\;key$}
        \State \Return \Call{ContainKey}{$curr,\;key,\;desc$}
        \EndFunction
        \Statex
        \Function{LocatePred}{$\textbf{ref Node*}\; pred,\;\hfill$ $\textbf{ref Node*}\; curr,\;\textbf{int}\;key$}
        \While {$curr \neq \NIL \AND curr.key < key$} \label{l:listpredcheck}
        \State $pred \gets curr$
        \State \Call{AdoptChild}{$curr$} \label{l:listpredhelp}
        \State $curr \gets \textsc{ClearMark}(curr.child[0])$ \label{l:listpredchild}
        \EndWhile
        \EndFunction
        \Statex
    \Function{ContainKey}{$\textbf{Node*}\; n,\; \textbf{int}\; key,\;\textbf{Desc*}\;desc$}
    \State \Return $\Call{IsExist}{n,key} \AND \Call{IsActive}{n,desc}$ \label{l:listcontain}
        \EndFunction
        \Statex
        \Function{IsExist}{$\textbf{Node*}\; n,\; \textbf{int}\; key$}
        \State \Return $n \neq \NIL \AND n.key = key$
        \EndFunction
        \Statex
        \Function{IsActive}{$\textbf{Node*}\;n,\; \textbf{Desc*}\; desc$}
        \If{$n.desc.status = \INPROGRESS$} \label{l:listactiveinprogress}
        \If{$n.desc = desc$} \label{l:listactivedesc}
        \State \Return $n.desc.ops[n.opid].type = \INSERT$
        \Else
        \State \Call{ExecuteOps}{$n.desc,\;n.opid+1$} \label{l:listactivehelp}
        \EndIf
        \EndIf
        \State \Return $(n.desc.ops[n.opid].type = \INSERT \hfill\break \AND n.desc.status = \SUCCEED) \hfill\break \OR (n.desc.ops[n.opid].type = \DELETE \hfill\break \AND n.desc.status = \FAIL)$ \label{l:listactivecond}
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Upon the completion of node traversal, we judge whether the list actually contains target key by two criteria on line~\algref{alg:listfind}{l:listcontain}: 1) the node exists and is reachable from the head; and 2) the node is active.
The first condition follows the sequential algorithm and is checked in the \texttt{IsExist} function.
The second condition is checked in the \texttt{IsActive} function.
We consider a node active if it is inserted by an \texttt{Insert} operation and the whole transaction commits successfully, or if it is inserted by a \texttt{Delete} operation and the transaction fails (line~\algref{alg:listfind}{l:listactivecond}).
Moreover, for in-progress transactions (line~\algref{alg:listfind}{l:listactiveinprogress}) we also need to recognize nodes inserted by the \texttt{Insert} operations in the same transaction as active. %TODO: correctness citation
This is done by testing the equality between the current transaction's descriptor and the descriptor of the transaction that inserted the node (line~\algref{alg:listfind}{l:listactivedesc}).
For all other in progress transactions, we invoke the helper method (line~\algref{alg:listfind}{l:listactivehelp}) and obtain the node's activeness after the transaction completes. %TODO: the help method should set status flag if opid is larger than the op size

\begin{algorithm}[t]
    \caption{Linked List Insert}
    \label{alg:listinsert}
    \begin{algorithmic}[1]
        \Function{Insert}{$\textbf{int}\;key,\;\textbf{Desc*}\;desc,\;\textbf{int}\;opid$}
        \State $\textbf{Node*}\; n \gets \text{\textbf{new Node}}$
        \State $n.key \gets key,\;n.val \gets val$
        \State $n.desc \gets desc,\;n.opid \gets opid$
        \State $\textbf{Node*}\; pred \gets \NIL,\;curr \gets head$
        \While{\TRUE} \label{l:listinsertwhile}
        \State \Call{LocatePred}{$pred,\;curr,\;key$}
        \If{\Call{ContainKey}{$curr,\;key,\;desc$}} \label{l:listinsertcontain}
        \State \Return $curr.desc = desc$ \label{l:listinsertdesc}
        \EndIf
        \State $\textbf{bool}\; replace \gets \Call{IsExist}{curr,\;key}$ \label{l:listinsertexist}
        \If {\Call{Replace}{$pred,\;curr,\;n,\;replace,\;0,\;0$}} \label{l:listinsertreplace}
        \State \Return \TRUE
        \Else
        \State $curr \gets \textsc{IsMakred}(pred.child[0]) \;?\; \hfill \break  \textsc{ClearMark}(pred.repl) : pred$ \label{l:listinsertpred}
        \State $pred \gets \NIL$ 
        \EndIf
        \EndWhile
        \EndFunction
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}[t]
    \caption{Linked List Delete}
    \label{alg:listdelete}
    \begin{algorithmic}[1]
        \Function{Delete}{$\textbf{int}\;key,\;\textbf{Desc*}\;desc,\;\textbf{int}\;opid$}
        \State $\textbf{Node*}\; n \gets \text{\textbf{new Node}}$
        \State $n.key \gets key,\;n.val \gets val$
        \State $n.desc \gets desc,\;n.opid \gets opid$
        \State $\textbf{Node*}\; pred \gets \NIL,\;curr \gets head$
        \While{\TRUE}
        \State \Call{LocatePred}{$pred,\;curr,\;key$}
        \If{$!\Call{IsExist}{curr,\;key}$} \label{l:listdeleteexist}
        \State \Return \FALSE
        \EndIf
        \If{!\Call{IsActive}{$curr,\;desc$}} \label{l:listdeleteactive}
        \State \Return $curr.desc = desc$
        \EndIf
        \If {\Call{Replace}{$pred,\;curr,\;n,\;\TRUE,\;0,\;0$}} \label{l:listdeletereplace}
        \State \Return \TRUE
        \Else
        \State $curr \gets \textsc{IsMakred}(pred.child[0]) \;?\;\hfill \break \textsc{ClearMark}(pred.repl) : pred$ 
        \State $pred \gets \NIL$ 
        \EndIf
        \EndWhile
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:listinsert} lists the \texttt{Insert} function.
After allocating a new node and set its field values, the function enters a CAS-based while loop (line~\algref{alg:listinsert}{l:listinsertwhile}).
The position to insert the new node is given by \texttt{LocatePred}.
Note that on line~\algref{alg:listinsert}{l:listinsertcontain} we check if the list already contains the target key.
If this is the case, we skip the insertion and return result code based on the equality of the transaction descriptors (line~\algref{alg:listinsert}{l:listinsertdesc}).
Due to the use of helping mechanism, the same \texttt{Insert} operation may be executed multiple times by different threads.
This condition check allows us to identify node inserted by other threads that executes the same transaction and thus ensures consistent result code is return for all execution paths.
This is important as all helping threads will try to set the transaction phase flag at the end of the execution; conflicts attempts on setting the transaction phase flag is possible if multiple execution of the same operation do not reach consensus on the result code.
On line~\algref{alg:listinsert}{l:listinsertreplace}, \texttt{Replace} is called to place the new node in the list.
If a node with same key exist but is inactive (line~\algref{alg:listinsert}{l:listinsertexist}), the existing node $curr$ will be replaced by the new node.
Should the CAS operation in \texttt{Replace} fails due to contention, we reset the traverse variable $pred$ and $curr$ and start the loop over again.
The traverse restart point depends on whether $pred$ node has been replaced by some other nodes, which can be inferred from the marked child pointer (line~\algref{alg:listinsert}{l:listinsertpred}).
When $pred$'s child node is marked, $pred$ is no longer reachable from the head.
We restart traverse from the node that replaces $pred$, whose reference was stored in the $pred$'s $repl$ field during the child adoption process (line~\algref{alg:replace}{l:adoptsetrepl}).
Otherwise, we simply start from $pred$.

The \texttt{Delete} operation listed in Algorithm~\ref{alg:listdelete} shares the same structure as the \texttt{Insert} operation.
The difference is that it inserts the new node only when the list contains the target key (line~\algref{alg:listdelete}{l:listdeleteexist} and~\algref{alg:listdelete}{l:listdeleteactive}), and when it does the new node always replaces an existing active node (the replace flag on line~\algref{alg:listdelete}{l:listdeletereplace} is set to true).

\subsection{Binary Search Tree}
\_

\section{Correctness}
\label{sec:correctness}
\_

\section{Experimental Results}
\label{sec:experiment}
\_

\section{Conclusion}
\label{sec:conclusion}
\_


\bibliographystyle{IEEEtran}
\bibliography{citation}

\end{document}
